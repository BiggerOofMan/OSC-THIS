# THIS (The Hell Is This?) - Environment Configuration
# Copy this to .env and fill in your API keys

# ==========================================
# LLM Configuration for Unknown Ingredient Research
# Choose ONE of the following options:
# ==========================================

# Option 1: Ollama (Local - Recommended for privacy)
# Install Ollama from https://ollama.ai/
# Run: ollama pull llama3.3:70b
# Uncomment the line below:
# OLLAMA_HOST=http://localhost:11434

# Option 2: Together AI (Cloud - Recommended for performance)
# Get API key from https://api.together.xyz/
# Uncomment and fill in your API key:
# TOGETHER_API_KEY=your_together_api_key_here

# Option 3: Custom OpenAI-compatible API
# For other providers that support OpenAI-compatible endpoints
# OPENAI_API_KEY=your_custom_api_key_here
# OPENAI_BASE_URL=https://your-provider.com/v1
# LLM_MODEL_NAME=llama-3.3-70b

# Option 4: OpenAI (Fallback)
# Uses GPT-3.5-Turbo if no other option is available
# OPENAI_API_KEY=your_openai_api_key_here

# ==========================================
# Other Service Configuration
# ==========================================

# OCR Configuration (Optional - improves accuracy)
# TESSDATA_PREFIX=/path/to/tessdata

# Translation Configuration (Optional - uses Google Translate by default)
# No additional configuration needed for basic translation

# ==========================================
# Example Complete Configurations:
# ==========================================

# For Ollama (Local):
# OLLAMA_HOST=http://localhost:11434

# For Together AI (Cloud):
# TOGETHER_API_KEY=your_together_api_key_here

# For OpenAI (Fallback):
# OPENAI_API_KEY=sk-your_openai_key_here